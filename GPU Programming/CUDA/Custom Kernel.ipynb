{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following the tutorial at https://thedatafrog.com/en/articles/cuda-kernel-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "from numba import cuda, vectorize\n",
    "import numpy as np\n",
    "import math\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['NUMBAPRO_LIBDEVICE'] = \"/usr/local/cuda-10.0/nvvm/libdevice\"\n",
    "os.environ['NUMBAPRO_NVVM'] = \"/usr/local/cuda-10.0/nvvm/lib64/libnvvm.so\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00000e+00, 1.00000e+00, 2.00000e+00, ..., 1.31069e+05,\n",
       "       1.31070e+05, 1.31071e+05], dtype=float32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.arange(4096*(2**5), dtype=np.float32)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 998 µs\n"
     ]
    }
   ],
   "source": [
    "%time _ = np.sqrt(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "@vectorize(['float32(float32)'], target='cuda')\n",
    "def gpu_sqrt(x):\n",
    "    return math.sqrt(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1.02 s\n"
     ]
    }
   ],
   "source": [
    "%time _ = gpu_sqrt(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "@cuda.jit\n",
    "def gpu_sqrt_kernel(x, out):\n",
    "    idx = cuda.grid(1)\n",
    "    out[idx] = math.sqrt(x[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cuda' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-5b82c3415215>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# move input data to the device\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0md_a\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcuda\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_device\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0md_out\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcuda\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice_array_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0md_a\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mthreads_per_block\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m32\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'cuda' is not defined"
     ]
    }
   ],
   "source": [
    "# move input data to the device\n",
    "d_a = cuda.to_device(a)\n",
    "d_out = cuda.device_array_like(d_a)\n",
    "\n",
    "threads_per_block = 32\n",
    "blocks_per_grid = math.ceil((len(a) + threads_per_block - 1)/threads_per_block)\n",
    "gpu_sqrt_kernel[blocks_per_grid, threads_per_block](d_a, d_out)\n",
    "print(blocks_per_grid)\n",
    "#wait for all the threads to compute\n",
    "#cuda.synchronize()\n",
    "new_a = d_out.copy_to_host()\n",
    "print(new_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(new_a-np.sqrt(a)).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 CUDA devices\n",
      "id 0     b'GeForce RTX 2060'                              [SUPPORTED]\n",
      "                      compute capability: 7.5\n",
      "                           pci device id: 0\n",
      "                              pci bus id: 1\n",
      "Summary:\n",
      "\t1/1 devices are supported\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cuda.detect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This simple kernel deals with a single element of the input array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "@cuda.jit\n",
    "def gpu_atan(x, out):\n",
    "    idx = cuda.grid(1)\n",
    "    out[idx] = math.atan(x[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the kernel is deployed, the GPU therefore needs to create as many threads as elements in the array, which potentially results in many blocks if the array is large.\n",
    "\n",
    "On the contrary, a striding kernel deals with several elements of the input array, using a loop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "@cuda.jit\n",
    "def gpu_atan_stride(x, out):\n",
    "    start = cuda.grid(1)\n",
    "    stride = cuda.gridsize(1)\n",
    "    for i in range(start, x.shape[0], stride):\n",
    "        out[i] = math.atan(x[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this way, a given thread deals with several elements, and the number of threads is kept under control. Threads keep doing work in a coordinated way, and the GPU is not wasting time creating and scheduling threads.\n",
    "\n",
    "Let's consider a small example with:\n",
    "\n",
    "an input data array of size 8\n",
    "blocks with 4 threads each\n",
    "Without striding, we need to use two blocks so 8 threads in total, each dealing with a single element in the array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 79.8 ms\n",
      "[0.        0.7853982 1.1071488 1.2490458 1.3258177 1.3734008 1.4056478\n",
      " 1.4288993]\n"
     ]
    }
   ],
   "source": [
    "a = np.arange(8, dtype=np.float32)\n",
    "d_a = cuda.to_device(a)\n",
    "d_out = cuda.device_array_like(d_a)\n",
    "\n",
    "# 2 blocks of 4 threads\n",
    "%time _ = gpu_atan[2,4](d_a, d_out)\n",
    "new_a = d_out.copy_to_host()\n",
    "print(d_out.copy_to_host())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With striding, we can use a single block with 4 threads, in which case each thread deals with two elements. Specifically, in the code above:\n",
    "\n",
    "start is the thread index, which is 0, 1, 2, 3 for the four threads, respectively.\n",
    "stride is the size of the grid, which is the total number of threads in the grid, here 4.\n",
    "x.shape[0] is the size of the input data array x , which is 8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 93.8 ms\n",
      "[0.        0.7853982 1.1071488 1.2490458 1.3258177 1.3734008 1.4056478\n",
      " 1.4288993]\n"
     ]
    }
   ],
   "source": [
    "# 1 block of 4 threads\n",
    "%time _ = gpu_atan_stride[1,4](d_a, d_out)\n",
    "print(d_out.copy_to_host())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance analysis ¶\n",
    "In this section, we will study the influence of striding and of the execution configuration parameters in the processing of a large array.\n",
    "\n",
    "So let's redefine our kernels (the simple one and the striding one:)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "@cuda.jit\n",
    "def gpu_atan(x, out):\n",
    "    idx = cuda.grid(1)\n",
    "    out[idx] = math.atan(x[idx])\n",
    "\n",
    "@cuda.jit\n",
    "def gpu_atan_stride(x, out):\n",
    "    start = cuda.grid(1)\n",
    "    stride = cuda.gridsize(1)\n",
    "    for i in range(start, x.shape[0], stride):\n",
    "        out[i] = math.atan(x[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we create a big array, we ship it to the device, and we create the output array on the device as usual:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.arange(256*1000000, dtype=np.float32)\n",
    "d_a = cuda.to_device(a)\n",
    "d_out = cuda.device_array_like(d_a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's see how fast we can process this array sequentially (in a single thread) on the GPU. We use the striding version here since, obviously, the simple version would only be able to process one element in a single thread."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 43.5 s\n"
     ]
    }
   ],
   "source": [
    "%time gpu_atan_stride[1, 1](d_a, d_out); cuda.synchronize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Processing these 256 million values in a single thread on the GPU took almost a minute. Let's see how parallel processing can help us. For that, we choose an execution configuration by following our simple rules, and we use the non-striding kernel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 99.8 ms\n"
     ]
    }
   ],
   "source": [
    "%time gpu_atan[1000000,256](d_a, d_out); cuda.synchronize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1.65 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.       , 0.7853982, 1.1071488, ..., 1.5707964, 1.5707964,\n",
       "       1.5707964], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time np.arctan(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's try and see if the striding version brings any performance improvement:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 12 ms\n"
     ]
    }
   ],
   "source": [
    "%time gpu_atan_stride[50000,256](d_a, d_out); cuda.synchronize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The gain is not very significant, you might have to rerun the two previous cells several times to convince yourself that there is indeed a gain. The amount of performance gain you'll get from striding will depend on the size of the input array, and on the work to be done by the kernel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multidimensional datasets : Matrix multiplication ¶\n",
    "So far, we've been working with one-dimensional arrays, making use of a 1D grid of threads.\n",
    "\n",
    "In the following 1D kernel, cuda.grid(1) returns a single index that identifies the position of the thread in the grid, and and cuda.gridsize(1) returns the length of the grid of threads:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "@cuda.jit\n",
    "def gpu_atan_stride(x, out):\n",
    "  start = cuda.grid(1)\n",
    "  stride = cuda.gridsize(1)\n",
    "  for i in range(start, x.shape[0], stride): \n",
    "    out[i] = math.atan(x[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we will see, these functions also provide an easy interface for the processing of 2D and 3D data.\n",
    "\n",
    "In this section, you will learn how to deploy a 2D grid of threads to process 2D data, and how to stride through 2D data. Then, you will implement a practical case: matrix multiplication."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A simple 2D kernel ¶\n",
    "To learn the basic tools to work with 2D data, please consider the following kernel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "@cuda.jit\n",
    "def gpu_2d(out):\n",
    "    i1, i2 = cuda.grid(2)\n",
    "    out[i1][i2] = i1*10 + i2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, this kernel does not even have an input. Its goal is only to encode and record in the output 2D array the coordinates of the current thread.\n",
    "\n",
    "Now, let's create the output data structure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.zeros(12).reshape(3,4)\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We copy this data structure to the device, and we deploy the kernel, before fetching the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  1.,  2.,  3.],\n",
       "       [10., 11., 12., 13.],\n",
       "       [20., 21., 22., 23.]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_a = cuda.to_device(a)\n",
    "\n",
    "blocks = (1, 2)\n",
    "\n",
    "threads_per_block = (3, 2)\n",
    "\n",
    "gpu_2d[blocks, threads_per_block](d_a)\n",
    "\n",
    "new_a = d_a.copy_to_host()\n",
    "new_a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first two columns were processed by the first block of threads, and the last two by the second block.\n",
    "\n",
    "Looking at the kernel code and at the output above, we see that i1 indexes the first dimension (the lines) while i2 indexes the second dimension (the columns).\n",
    "\n",
    "As in the 1D case, it's necessary to make sure that the grid covers the whole output data structure. For example, if we mess up in the description of the block structure, the last two columns remain unprocessed, and we actually access unallowed memory \"below\" our 2D array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  1.,  0.,  0.],\n",
       "       [10., 11.,  0.,  0.],\n",
       "       [20., 21.,  0.,  0.]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# need to send back the matrix of zeros \n",
    "# to reset it on the device\n",
    "d_a = cuda.to_device(a)\n",
    "# here we mess up: \n",
    "# we require two blocks on top of each other, \n",
    "# and we get a grid with a total height of 2x3=6 \n",
    "# and a total width of 1x2=2...\n",
    "gpu_2d[(2,1), (3,2)](d_a)\n",
    "d_a.copy_to_host()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2D striding ¶\n",
    "Striding in 2D is not much more difficult that in 1D. Again, let's take a very simple example, and first make sure that our implementation of striding is working:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "@cuda.jit\n",
    "def gpu_2d_stride(out):\n",
    "    # Get the thread coordinates in 2d\n",
    "    s1, s2 = cuda.grid(2)\n",
    "    # get the grid sie in 2d\n",
    "    d1, d2 = cuda.gridsize(2)\n",
    "    for i1 in range(s1, out.shape[0], d1):\n",
    "        for i2 in range(s2, out.shape[1], d2):\n",
    "            out[i1][i2] = i1*10 + i2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We reset the output data on the device, and we deploy a single (3,2) block. The grid therefore covers only half of the output array. But the striding will move the grid in the output array, making sure that the whole array is covered:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  1.,  2.,  3.],\n",
       "       [10., 11., 12., 13.],\n",
       "       [20., 21., 22., 23.]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_a = cuda.to_device(a)\n",
    "gpu_2d_stride[(1,), (3,2)](d_a)\n",
    "new_a = d_a.copy_to_host()\n",
    "new_a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get the same results as without striding. Now let's visualize striding with a slightly different kernel, which will register the starting point (s1, s2) of each thread:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "@cuda.jit\n",
    "def gpu_2d_start(out):\n",
    "    # get the thread coodinates in 2d\n",
    "    s1, s2 = cuda.grid(2)\n",
    "    # get the grid size in 2d\n",
    "    d1, d2 = cuda.gridsize(2)\n",
    "    for i1 in range(s1, out.shape[0], d1):\n",
    "        for i2 in range(s2, out.shape[1], d2):\n",
    "            #note the difference in using s rather than i\n",
    "            out[i1][i2] = s1*10 + s2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  1.,  0.,  1.],\n",
       "       [10., 11., 10., 11.],\n",
       "       [20., 21., 20., 21.]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_a = cuda.to_device(a)\n",
    "gpu_2d_start[(1,), (3,2)](d_a)\n",
    "d_a.copy_to_host()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The elements with the same value are processed by the same thread, and we see that there is only one stride to the right.\n",
    "\n",
    "Extending our 2D array, we see that striding occurs in both direction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  1.,  0.,  1.],\n",
       "       [10., 11., 10., 11.],\n",
       "       [20., 21., 20., 21.],\n",
       "       [ 0.,  1.,  0.,  1.]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.zeros(16).reshape(4,4)\n",
    "d_a = cuda.to_device(a)\n",
    "gpu_2d_start[(1,), (3,2)](d_a)\n",
    "d_a.copy_to_host()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2D matrix multiplication : theory ¶\n",
    "Implement a 2D matrix multiplication kernel is an excellent way to confirm that we now master striding in 2D.\n",
    "\n",
    "First, a little reminder. Two matrices A of size (m,n) and B of size (n,p) can be multiplied since the number of colums of matrix A is equal to the number of lines of matrix B. The product matrix C is then of size (m,p). And the value of one of the coefficients of matrix C is given by:\n",
    "\n",
    " \n",
    "This might seem a bit complicated if you are new to linear algebra or haven't used it in a long time. So let's take a simple example in code. We create two matrices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 2]\n",
      " [3 4 5]]\n",
      "[[ 0  1  2  3]\n",
      " [ 4  5  6  7]\n",
      " [ 8  9 10 11]]\n"
     ]
    }
   ],
   "source": [
    "a = np.arange(6).reshape(2,3)\n",
    "b = np.arange(12).reshape(3,4)\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[20, 23, 26, 29],\n",
       "       [56, 68, 80, 92]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = a.dot(b)\n",
    "c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matrix a is of size (2,3) and matrix b of size (3,4) , so the product matrix is of size (2,4) .\n",
    "\n",
    "Let's consider for example the coefficient on the first line and second column of the product matrix, which is 23. This is c01. The summation equation above tells us that this coefficient is obtained by taking the coefficients of the first line of matrix a, and by multiplying them with the coefficients of the second column of matrix b, respectively, before summing everything.\n",
    "\n",
    "We get: c01 = a00*b01 + a01*b11 + a02*b21 = 0*1 + 1*5 + 2*9 = 23"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A 2D matrix multiplication kernel ¶\n",
    "As a first step, we will implement matrix multiplication without striding. So we will need one thread for each element in the output matrix. Here is the kernel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "@cuda.jit\n",
    "def multiply(a, b, c):\n",
    "    i1, i2 = cuda.grid(2)\n",
    "    coeff = 0\n",
    "    for k in range(b.shape[0]):\n",
    "        coeff += a[i1][k]*b[k][i2]\n",
    "    c[i1, i2] = coeff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1024, 1024)\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "d_a = cuda.to_device(a)\n",
    "d_b = cuda.to_device(b)\n",
    "c = np.zeros((a.shape[0], b.shape[1]))\n",
    "print(c.shape)\n",
    "d_c = cuda.to_device(c)\n",
    "threads_per_block = 4\n",
    "blocks_per_grid_1 = math.ceil((c.shape[0] + threads_per_block - 1)/threads_per_block)\n",
    "blocks_per_grid_2 = math.ceil((c.shape[1] + threads_per_block - 1)/threads_per_block)\n",
    "print(d_c.copy_to_host())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets try with a bigger array and see the time improvement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 8\n",
    "a = np.arange(2**k).reshape(2**int(k/2), 2**int(k/2))\n",
    "b = np.arange(2**k).reshape(2**int(k/2), 2**int(k/2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[  333312,   333808,   334304, ...,   347696,   348192,   348688],\n",
       "       [  841216,   842736,   844256, ...,   885296,   886816,   888336],\n",
       "       [ 1349120,  1351664,  1354208, ...,  1422896,  1425440,  1427984],\n",
       "       ...,\n",
       "       [15062528, 15092720, 15122912, ..., 15938096, 15968288, 15998480],\n",
       "       [15570432, 15601648, 15632864, ..., 16475696, 16506912, 16538128],\n",
       "       [16078336, 16110576, 16142816, ..., 17013296, 17045536, 17077776]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time a.dot(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 32)\n"
     ]
    },
    {
     "ename": "CudaAPIError",
     "evalue": "[1] Call to cuLaunchKernel results in CUDA_ERROR_INVALID_VALUE",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mCudaAPIError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\numba\\cuda\\compiler.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    833\u001b[0m         \u001b[0mkernel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mspecialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    834\u001b[0m         \u001b[0mcfg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkernel\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgriddim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mblockdim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msharedmem\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 835\u001b[1;33m         \u001b[0mcfg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    836\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    837\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mspecialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\numba\\cuda\\compiler.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    592\u001b[0m         griddim, blockdim = normalize_kernel_dimensions(self.griddim,\n\u001b[0;32m    593\u001b[0m                                                         self.blockdim)\n\u001b[1;32m--> 594\u001b[1;33m         self._kernel_call(args=args,\n\u001b[0m\u001b[0;32m    595\u001b[0m                           \u001b[0mgriddim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgriddim\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    596\u001b[0m                           \u001b[0mblockdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mblockdim\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\numba\\cuda\\compiler.py\u001b[0m in \u001b[0;36m_kernel_call\u001b[1;34m(self, args, griddim, blockdim, stream, sharedmem)\u001b[0m\n\u001b[0;32m    670\u001b[0m                                    sharedmem=sharedmem)\n\u001b[0;32m    671\u001b[0m         \u001b[1;31m# Invoke kernel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 672\u001b[1;33m         \u001b[0mcu_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mkernelargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    673\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    674\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\numba\\cuda\\cudadrv\\driver.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1926\u001b[0m             \u001b[0mstreamhandle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1927\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1928\u001b[1;33m         launch_kernel(self.handle, self.griddim, self.blockdim,\n\u001b[0m\u001b[0;32m   1929\u001b[0m                       self.sharedmem, streamhandle, args)\n\u001b[0;32m   1930\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\numba\\cuda\\cudadrv\\driver.py\u001b[0m in \u001b[0;36mlaunch_kernel\u001b[1;34m(cufunc_handle, griddim, blockdim, sharedmem, hstream, args)\u001b[0m\n\u001b[0;32m   1965\u001b[0m     \u001b[0mparams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mc_void_p\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparam_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mparam_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1966\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1967\u001b[1;33m     driver.cuLaunchKernel(cufunc_handle,\n\u001b[0m\u001b[0;32m   1968\u001b[0m                           \u001b[0mgx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgz\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1969\u001b[0m                           \u001b[0mbx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mby\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbz\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\numba\\cuda\\cudadrv\\driver.py\u001b[0m in \u001b[0;36msafe_cuda_api_call\u001b[1;34m(*args)\u001b[0m\n\u001b[0;32m    293\u001b[0m             \u001b[0m_logger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'call driver api: %s'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlibfn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    294\u001b[0m             \u001b[0mretcode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlibfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 295\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretcode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    296\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0msafe_cuda_api_call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    297\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\numba\\cuda\\cudadrv\\driver.py\u001b[0m in \u001b[0;36m_check_error\u001b[1;34m(self, fname, retcode)\u001b[0m\n\u001b[0;32m    328\u001b[0m                     \u001b[0m_logger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcritical\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_getpid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    329\u001b[0m                     \u001b[1;32mraise\u001b[0m \u001b[0mCudaDriverError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"CUDA initialized before forking\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 330\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mCudaAPIError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mretcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    331\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    332\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_device\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevnum\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mCudaAPIError\u001b[0m: [1] Call to cuLaunchKernel results in CUDA_ERROR_INVALID_VALUE"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-333312.0"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_a = cuda.to_device(a)\n",
    "d_b = cuda.to_device(b)\n",
    "c = np.zeros((a.shape[0], b.shape[1]))\n",
    "print(c.shape)\n",
    "d_c = cuda.to_device(c)\n",
    "\n",
    "threads_per_block = 512\n",
    "blocks_per_grid_1 = 2\n",
    "blocks_per_grid_2 = 2\n",
    "\n",
    "%time _ = multiply[(1, blocks_per_grid_2), (threads_per_block,threads_per_block)](d_a, d_b, d_c)\n",
    "a2 = d_c.copy_to_host()\n",
    "(a2-a.dot(b)).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1024, 1024)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1024"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "512*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "@cuda.jit\n",
    "def matmul(A, B, C):\n",
    "    \"\"\"Perform square matrix multiplication of C = A * B\n",
    "    \"\"\"\n",
    "    i, j = cuda.grid(2)\n",
    "    if i < C.shape[0] and j < C.shape[1]:\n",
    "        tmp = 0.\n",
    "        for k in range(A.shape[1]):\n",
    "            tmp += A[i, k] * B[k, j]\n",
    "        C[i, j] = tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 128)\n",
      "Wall time: 0 ns\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "17179869184.0"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_a = cuda.to_device(a)\n",
    "d_b = cuda.to_device(b)\n",
    "c = np.zeros((a.shape[0], b.shape[1]))\n",
    "print(c.shape)\n",
    "d_c = cuda.to_device(c)\n",
    "\n",
    "threads_per_block = 32\n",
    "blocks_per_grid_1 = 2000\n",
    "blocks_per_grid_2 = 2000\n",
    "\n",
    "%time _ = matmul[(blocks_per_grid_1, blocks_per_grid_2), (threads_per_block,threads_per_block)](d_a, d_b, d_c)\n",
    "c = d_c.copy_to_host()\n",
    "(c-a.dot(b)).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  88432640,   88440768,   88448896, ...,   89448640,   89456768,\n",
       "          89464896],\n",
       "       [ 221601792,  221626304,  221650816, ...,  224665792,  224690304,\n",
       "         224714816],\n",
       "       [ 354770944,  354811840,  354852736, ...,  359882944,  359923840,\n",
       "         359964736],\n",
       "       ...,\n",
       "       [-445292544, -443236416, -441180288, ..., -188276544, -186220416,\n",
       "        -184164288],\n",
       "       [-312123392, -310050880, -307978368, ...,  -53059392,  -50986880,\n",
       "         -48914368],\n",
       "       [-178954240, -176865344, -174776448, ...,   82157760,   84246656,\n",
       "          86335552]])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.dot(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[8.84326400e+07, 8.84407680e+07, 8.84488960e+07, ...,\n",
       "        8.94486400e+07, 8.94567680e+07, 8.94648960e+07],\n",
       "       [2.21601792e+08, 2.21626304e+08, 2.21650816e+08, ...,\n",
       "        2.24665792e+08, 2.24690304e+08, 2.24714816e+08],\n",
       "       [3.54770944e+08, 3.54811840e+08, 3.54852736e+08, ...,\n",
       "        3.59882944e+08, 3.59923840e+08, 3.59964736e+08],\n",
       "       ...,\n",
       "       [1.67345766e+10, 1.67366328e+10, 1.67386889e+10, ...,\n",
       "        1.69915926e+10, 1.69936488e+10, 1.69957049e+10],\n",
       "       [1.68677458e+10, 1.68698183e+10, 1.68718908e+10, ...,\n",
       "        1.71268098e+10, 1.71288823e+10, 1.71309548e+10],\n",
       "       [1.70009149e+10, 1.70030038e+10, 1.70050927e+10, ...,\n",
       "        1.72620269e+10, 1.72641158e+10, 1.72662047e+10]])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1024"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "32*32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "TPB = 16\n",
    "\n",
    "@cuda.jit\n",
    "def fast_matmul(A, B, C):\n",
    "    # Define an array in the shared memory\n",
    "    # The size and type of the arrays must be known at compile time\n",
    "    sA = cuda.shared.array(shape=(TPB, TPB), dtype=float32)\n",
    "    sB = cuda.shared.array(shape=(TPB, TPB), dtype=float32)\n",
    "\n",
    "    x, y = cuda.grid(2)\n",
    "\n",
    "    tx = cuda.threadIdx.x\n",
    "    ty = cuda.threadIdx.y\n",
    "    bpg = cuda.gridDim.x    # blocks per grid\n",
    "\n",
    "    if x >= C.shape[0] and y >= C.shape[1]:\n",
    "        # Quit if (x, y) is outside of valid C boundary\n",
    "        return\n",
    "\n",
    "    # Each thread computes one element in the result matrix.\n",
    "    # The dot product is chunked into dot products of TPB-long vectors.\n",
    "    tmp = 0.\n",
    "    for i in range(bpg):\n",
    "        # Preload data into shared memory\n",
    "        sA[tx, ty] = A[x, ty + i * TPB]\n",
    "        sB[tx, ty] = B[tx + i * TPB, y]\n",
    "\n",
    "        # Wait until all threads finish preloading\n",
    "        cuda.syncthreads()\n",
    "\n",
    "        # Computes partial product on the shared memory\n",
    "        for j in range(TPB):\n",
    "            tmp += sA[tx, j] * sB[j, ty]\n",
    "\n",
    "        # Wait until all threads finish computing\n",
    "        cuda.syncthreads()\n",
    "\n",
    "    C[x, y] = tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16, 16)\n",
      "Wall time: 298 ms\n"
     ]
    },
    {
     "ename": "CudaAPIError",
     "evalue": "[700] Call to cuMemcpyDtoH results in UNKNOWN_CUDA_ERROR",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mCudaAPIError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-4e20efaccc17>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'time'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'_ = fast_matmul[(blocks_per_grid_1, blocks_per_grid_2), (threads_per_block,threads_per_block)](d_a, d_b, d_c)'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[0mc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0md_c\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy_to_host\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\numba\\cuda\\cudadrv\\devices.py\u001b[0m in \u001b[0;36m_require_cuda_context\u001b[1;34m(*args, **kws)\u001b[0m\n\u001b[0;32m    222\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_require_cuda_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkws\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    223\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0m_runtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 224\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkws\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    225\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    226\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0m_require_cuda_context\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\numba\\cuda\\cudadrv\\devicearray.py\u001b[0m in \u001b[0;36mcopy_to_host\u001b[1;34m(self, ary, stream)\u001b[0m\n\u001b[0;32m    262\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    263\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0malloc_size\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 264\u001b[1;33m             \u001b[0m_driver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice_to_host\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhostary\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0malloc_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    265\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    266\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mary\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\numba\\cuda\\cudadrv\\driver.py\u001b[0m in \u001b[0;36mdevice_to_host\u001b[1;34m(dst, src, size, stream)\u001b[0m\n\u001b[0;32m   2267\u001b[0m         \u001b[0mfn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuMemcpyDtoH\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2268\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2269\u001b[1;33m     \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhost_pointer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdst\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice_pointer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mvarargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2270\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2271\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\numba\\cuda\\cudadrv\\driver.py\u001b[0m in \u001b[0;36msafe_cuda_api_call\u001b[1;34m(*args)\u001b[0m\n\u001b[0;32m    293\u001b[0m             \u001b[0m_logger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'call driver api: %s'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlibfn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    294\u001b[0m             \u001b[0mretcode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlibfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 295\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretcode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    296\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0msafe_cuda_api_call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    297\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\numba\\cuda\\cudadrv\\driver.py\u001b[0m in \u001b[0;36m_check_error\u001b[1;34m(self, fname, retcode)\u001b[0m\n\u001b[0;32m    328\u001b[0m                     \u001b[0m_logger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcritical\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_getpid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    329\u001b[0m                     \u001b[1;32mraise\u001b[0m \u001b[0mCudaDriverError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"CUDA initialized before forking\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 330\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mCudaAPIError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mretcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    331\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    332\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_device\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevnum\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mCudaAPIError\u001b[0m: [700] Call to cuMemcpyDtoH results in UNKNOWN_CUDA_ERROR"
     ]
    }
   ],
   "source": [
    "d_a = cuda.to_device(a)\n",
    "d_b = cuda.to_device(b)\n",
    "c = np.zeros((a.shape[0], b.shape[1]))\n",
    "print(c.shape)\n",
    "d_c = cuda.to_device(c)\n",
    "\n",
    "threads_per_block = 32\n",
    "blocks_per_grid_1 = 20\n",
    "blocks_per_grid_2 = 20\n",
    "\n",
    "%time _ = fast_matmul[(blocks_per_grid_1, blocks_per_grid_2), (threads_per_block,threads_per_block)](d_a, d_b, d_c)\n",
    "c = d_c.copy_to_host()\n",
    "(c-a.dot(b)).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
